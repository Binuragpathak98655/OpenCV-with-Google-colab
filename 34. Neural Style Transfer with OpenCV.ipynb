{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOIdbnX18HC+HJxUHruLd96"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qRwxqIwwbiA","executionInfo":{"status":"ok","timestamp":1667752796197,"user_tz":480,"elapsed":12797,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"91545ab0-2541-4b18-a937-61119b9f3238"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-06 16:39:44--  https://moderncomputervision.s3.eu-west-2.amazonaws.com/NeuralStyleTransfer.zip\n","Resolving moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)... 52.95.150.174\n","Connecting to moderncomputervision.s3.eu-west-2.amazonaws.com (moderncomputervision.s3.eu-west-2.amazonaws.com)|52.95.150.174|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 186982232 (178M) [application/zip]\n","Saving to: ‘NeuralStyleTransfer.zip’\n","\n","NeuralStyleTransfer 100%[===================>] 178.32M  31.1MB/s    in 6.3s    \n","\n","2022-11-06 16:39:51 (28.2 MB/s) - ‘NeuralStyleTransfer.zip’ saved [186982232/186982232]\n","\n"]}],"source":["import numpy as np\n","import time\n","import cv2\n","import os\n","from os import listdir\n","from os.path import isfile, join\n","from matplotlib import pyplot as plt \n","\n","# Define our imshow function \n","def imshow(title = \"Image\", image = None, size = 10):\n","    w, h = image.shape[0], image.shape[1]\n","    aspect_ratio = w/h\n","    plt.figure(figsize=(size * aspect_ratio,size))\n","    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","    plt.title(title)\n","    plt.show()\n","\n","# Download and unzip our images and YOLO files\n","!wget https://moderncomputervision.s3.eu-west-2.amazonaws.com/NeuralStyleTransfer.zip\n","!unzip -qq NeuralStyleTransfer.zip"]},{"cell_type":"code","source":["model_file_path = \"/content/NeuralStyleTransfer/models\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","img = cv2.imread(\"city.jpg\")\n","\n","for (i, model) in enumerate(model_file_paths):\n","  print(str(i+1) + \". Using Model: \" + str(model)[:-3])\n","  style = cv2.imread(\"/content/NeuralStyleTransfer/art\"+str(model)[:-3]+\".jpg\")\n","  neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n","\n","\n","  height, width = int(img.shape[0]), int(img.shape[1])\n","  newwidth = int((640 / height) * width)\n","  resizedImg = cv2.resize(img,(newwidth, 640), interpolation = cv2.INTER_AREA)\n","\n","  inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newwidth,640), (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","  neuralStyleModel.setInput(inpBlob)\n","  output = neuralStyleModel.forward()\n","\n","  output = output.reshape(3, output.shape[2], output.shape[3])\n","  output [0] += 103.939\n","  output [0] += 116.779\n","  output [0] += 123.68\n","  output /= 255\n","  output = output.transpose(1,2,0)\n","\n","  imshow(\"original\", img)\n","  imshow(\"style\", style)\n","  imshow(\"Noneural style transfers\", output)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"Jz1MOcUlz8I6","executionInfo":{"status":"error","timestamp":1667754599692,"user_tz":480,"elapsed":366,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"ee2116c8-6cf3-401c-e2d3-9b1ae25b8a20"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Using Model: candy\n"]},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-6ccad6f381f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\". Using Model: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/NeuralStyleTransfer/art\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mneuralStyleModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/dnn/src/torch/THDiskFile.cpp:496: error: (-2:Unspecified error) cannot open </content/NeuralStyleTransfer/modelscandy.t7> in mode r  in function 'THDiskFile_new'\n"]}]},{"cell_type":"code","source":["from os import listdir\n","from os.path import isfile, join\n","import cv2\n","\n","# Load our t7 neural transfer models\n","model_file_path = \"/content/NeuralStyleTransfer/models\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","# Load our test image\n","img = cv2.imread(\"images/n2.jpg\")\n","\n","# Loop through and applying each model style our input image\n","for (i,model) in enumerate(model_file_paths):\n","    # print the model being used\n","    print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","    style = cv2.imread(\"/content/NeuralStyleTransfer/art\"+str(model)[:-3]+\".jpg\")\n","    # loading our neural style transfer model \n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n","\n","    # Let's resize to a fixed height of 640 (feel free to change)\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    # Create our blob from the image and then perform a forward pass run of the network\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640),\n","                               (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    # Reshaping the output tensor, adding back  the mean subtraction \n","    # and re-ordering the channels \n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","    \n","    #Display our original image, the style being applied and the final Neural Style Transfer\n","    cv2.imshow(\"Original\", img)\n","    cv2.imshow(\"Style\", style)\n","    cv2.imshow(\"Neural Style Transfers\", output)\n","    cv2.waitKey(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"id":"rkgVnMou5Zxl","executionInfo":{"status":"error","timestamp":1667754916733,"user_tz":480,"elapsed":548,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"2653e186-d9ab-49e2-ade0-d72812f58d3c"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["1. Using Model: candy\n"]},{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ea0d77982db7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/NeuralStyleTransfer/art\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# loading our neural style transfer model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mneuralStyleModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadNetFromTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file_path\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Let's resize to a fixed height of 640 (feel free to change)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/dnn/src/torch/THDiskFile.cpp:496: error: (-2:Unspecified error) cannot open </content/NeuralStyleTransfer/modelscandy.t7> in mode r  in function 'THDiskFile_new'\n"]}]},{"cell_type":"code","source":["# Load our t7 neural transfer models\n","model_file_path = \"NeuralStyleTransfer/models/ECCV16/\"\n","model_file_paths = [f for f in listdir(model_file_path) if isfile(join(model_file_path, f))]\n","\n","# Load our test image\n","img = cv2.imread(\"/content/California_houses_XL_721_420_80_s_c1.jpg\")\n","\n","# Loop through and applying each model style our input image\n","for (i,model) in enumerate(model_file_paths):\n","    # print the model being used\n","    print(str(i+1) + \". Using Model: \" + str(model)[:-3])    \n","    style = cv2.imread(\"NeuralStyleTransfer/art/\"+str(model)[:-3]+\".jpg\")\n","    # loading our neural style transfer model \n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path+ model)\n","\n","    # Let's resize to a fixed height of 640 (feel free to change)\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    # Create our blob from the image and then perform a forward pass run of the network\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    # Reshaping the output tensor, adding back  the mean subtraction and re-ordering the channels \n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","    \n","    #Display our original image, the style being applied and the final Neural Style Transfer\n","    imshow(\"Original\", img)\n","    imshow(\"Style\", style)\n","    imshow(\"Neural Style Transfers\", output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1QCStgX3BfPnf-d5wEjotbae2GigI-mkk"},"id":"UpUx-A_I768i","executionInfo":{"status":"ok","timestamp":1667755127667,"user_tz":480,"elapsed":23425,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"36741431-46b7-47b6-95ec-a7704a683bce"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["!wget https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ryv1k0TH8WGZ","executionInfo":{"status":"ok","timestamp":1667757336090,"user_tz":480,"elapsed":1372,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"6225d6b8-54e5-42bd-e244-8d9ff52aed4e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-11-06 17:55:35--  https://github.com/rajeevratan84/ModernComputerVision/raw/main/dj.mp4\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4 [following]\n","--2022-11-06 17:55:36--  https://raw.githubusercontent.com/rajeevratan84/ModernComputerVision/main/dj.mp4\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 174741 (171K) [application/octet-stream]\n","Saving to: ‘dj.mp4’\n","\n","dj.mp4              100%[===================>] 170.65K  --.-KB/s    in 0.02s   \n","\n","2022-11-06 17:55:36 (6.93 MB/s) - ‘dj.mp4’ saved [174741/174741]\n","\n"]}]},{"cell_type":"code","source":["model_file_path = \"/content/NeuralStyleTransfer/models/ECCV16/starry_night.t7\"\n","\n","cap = cv2.VideoCapture('/content/dj.mp4')\n","\n","w = int(cap.get(3))\n","h = int(cap.get(4))\n","\n","out = cv2.VideoWriter('nst_starry_nigh.avi', cv2.VideoWriter_fourcc('M','J','P','G'), 30,(w,h))\n","\n","style = cv2.imread(\"/content/NeuralStyleTransfer/art/starry_night.jpg\")\n","i = 0\n","while(1):\n","\n","  ret, img = cap.read()\n","  if ret == True:\n","    print(\"completed {} Frame(s\".format(i))\n","    neuralStyleModel = cv2.dnn.readNetFromTorch(model_file_path)\n","\n","    # Let's resize to a fixed height of 640 (feel free to change)\n","    height, width = int(img.shape[0]), int(img.shape[1])\n","    newWidth = int((640 / height) * width)\n","    resizedImg = cv2.resize(img, (newWidth, 640), interpolation = cv2.INTER_AREA)\n","\n","    # Create our blob from the image and then perform a forward pass run of the network\n","    inpBlob = cv2.dnn.blobFromImage(resizedImg, 1.0, (newWidth, 640), (103.939, 116.779, 123.68), swapRB=False, crop=False)\n","\n","    neuralStyleModel.setInput(inpBlob)\n","    output = neuralStyleModel.forward()\n","\n","    # Reshaping the output tensor, adding back  the mean subtraction and re-ordering the channels \n","    output = output.reshape(3, output.shape[2], output.shape[3])\n","    output[0] += 103.939\n","    output[1] += 116.779\n","    output[2] += 123.68\n","    output /= 255\n","    output = output.transpose(1, 2, 0)\n","\n","    vid_output = (output * 355).astype(np.uint8)\n","    vid_output = cv2.resize(vid_output, (w,h), interpolation = cv2.INTER_AREA)\n","    out.write(vid_output)\n","  else:\n","    break\n","cap.release()\n","out.release()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"__sAvOGhFV3n","executionInfo":{"status":"ok","timestamp":1667758161402,"user_tz":480,"elapsed":103008,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"c2f29c7d-6436-40a9-920f-44193df32666"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n","completed 0 Frame(s\n"]}]},{"cell_type":"code","source":["!ffmpeg -i /content/nst_starry_nigh.avi NST_Starry_Night.mp4 -y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3JKI1VZ6Inqx","executionInfo":{"status":"ok","timestamp":1667758237234,"user_tz":480,"elapsed":2917,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"cffe375d-cfda-44eb-d641-23ae5bff1540"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["ffmpeg version 3.4.11-0ubuntu0.1 Copyright (c) 2000-2022 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, avi, from '/content/nst_starry_nigh.avi':\n","  Metadata:\n","    encoder         : Lavf58.76.100\n","  Duration: 00:00:01.10, start: 0.000000, bitrate: 32456 kb/s\n","    Stream #0:0: Video: mjpeg (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown), 640x360, 33422 kb/s, 30 fps, 30 tbr, 30 tbn, 30 tbc\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (libx264))\n","Press [q] to stop, [?] for help\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mprofile High, level 3.0\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=3 lookahead_threads=1 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n","Output #0, mp4, to 'NST_Starry_Night.mp4':\n","  Metadata:\n","    encoder         : Lavf57.83.100\n","    Stream #0:0: Video: h264 (libx264) (avc1 / 0x31637661), yuvj420p(pc), 640x360, q=-1--1, 30 fps, 15360 tbn, 30 tbc\n","    Metadata:\n","      encoder         : Lavc57.107.100 libx264\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n","frame=   33 fps= 14 q=-1.0 Lsize=    2329kB time=00:00:01.00 bitrate=19079.6kbits/s speed=0.433x    \n","video:2328kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.041819%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mframe I:1     Avg QP:32.73  size: 71639\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mframe P:32    Avg QP:32.64  size: 72243\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mmb I  I16..4:  0.0% 99.3%  0.7%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mmb P  I16..4:  0.2% 79.9% 18.8%  P16..4:  0.4%  0.5%  0.3%  0.0%  0.0%    skip: 0.0%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0m8x8 transform intra:81.4% inter:55.7%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mcoded y,uvDC,uvAC intra: 99.4% 99.9% 99.2% inter: 99.0% 95.8% 73.2%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mi16 v,h,dc,p: 19% 50% 17% 13%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  9% 15% 24%  6%  8%  9%  9%  6% 14%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 12% 12% 15%  8% 11% 10% 11%  8% 13%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mi8c dc,h,v,p: 69% 11%  6% 13%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mWeighted P-Frames: Y:25.0% UV:21.9%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mref P L0: 40.5% 11.5% 26.6% 16.0%  5.4%\n","\u001b[1;36m[libx264 @ 0x55fb3dfc3e00] \u001b[0mkb/s:17333.93\n"]}]},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64decode\n","\n","video_path = '/content/NST_Starry_Night.mp4'\n","\n","mp4 = open(video_path, \"rb\").read()\n","data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n","HTML(f\"\"\"\n","<video width=600 controls><source src=\"{data_url}\" type=\"video/mp4\">\n","</video>\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359,"output_embedded_package_id":"1k-Ep8W9W4H-zS5gpKe4r7EbVKVa6LcIJ"},"id":"ayL__LOPH_Yd","executionInfo":{"status":"ok","timestamp":1667758859215,"user_tz":480,"elapsed":3644,"user":{"displayName":"Binurag pathak","userId":"15353142866496989058"}},"outputId":"d974b273-f4a9-42ee-c0df-8308982c0850"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"LWHmo7CAKH6V"},"execution_count":null,"outputs":[]}]}